<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://tech.k10n.me/feed.xml" rel="self" type="application/atom+xml" /><link href="https://tech.k10n.me/" rel="alternate" type="text/html" /><updated>2025-07-23T00:39:41+00:00</updated><id>https://tech.k10n.me/feed.xml</id><title type="html">Cloud.CH</title><subtitle>소프트웨어 개발에 대한 경험과 지식을 이야기합니다.</subtitle><entry><title type="html">Kubernetes ConfigMap, Secret 깊게 이해하기</title><link href="https://tech.k10n.me/2025/07/16/configmap-secret.html" rel="alternate" type="text/html" title="Kubernetes ConfigMap, Secret 깊게 이해하기" /><published>2025-07-16T00:00:00+00:00</published><updated>2025-07-23T00:39:24+00:00</updated><id>https://tech.k10n.me/2025/07/16/configmap-secret</id><content type="html" xml:base="https://tech.k10n.me/2025/07/16/configmap-secret.html">&lt;h1 id=&quot;configmap과-secret이란&quot;&gt;ConfigMap과 Secret이란?&lt;/h1&gt;

&lt;p&gt;ConfigMap과 Secret은 컨테이너화된 애플리케이션의 설정을 이미지와 분리하기 위해 탄생한 쿠버네티스 API 오브젝트로 이는 &lt;a href=&quot;https://en.wikipedia.org/wiki/Twelve-Factor_App_methodology&quot;&gt;12-Factor App&lt;/a&gt; 원칙 중 하나인 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Config(주요 설정은 환경변수로 저장하거나 저장소에 커밋되지 않는 파일에 저장한다.)철학&lt;/code&gt;을 쿠버네티스 환경에서 구현하는 핵심적인 방법이다.&lt;/p&gt;

&lt;h2 id=&quot;configmap을-알아보자&quot;&gt;ConfigMap을 알아보자&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;ConfigMap은 민감하지 않은 설정 데이터를&lt;/strong&gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Key-Value&lt;/code&gt; &lt;strong&gt;형태로 저장하는데 사용하는 API 오브젝트이다.&lt;/strong&gt; Pod는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;볼륨&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENV&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;커맨드 라인&lt;/code&gt; 등으로 ConfigMap을 활용할 수 있다.&lt;/p&gt;

&lt;p&gt;예를 들어 로깅 레벨 지정, 외부 서비스 엔드 포인트, 기능 플래그 등이 해당되며, ConfigMap을 사용하면 컨테이너 이미지에서 환경별 구성을 분리하여, 애플리케이션을 쉽게 이식할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;추가로 ConfigMap은 많은 양의 데이터를 보유하도록 설계되지 않았다.&lt;/strong&gt; 컨피그맵에 저장된 데이터는 &lt;strong&gt;1MiB를 초과할 수 없으며&lt;/strong&gt; 이 제한보다 큰 설정을 저장해야 하는 경우, 볼륨 마운트하는 것을 고려하거나 별도의 데이터베이스 또는 파일 서비스를 사용할 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;secret을-알아보자&quot;&gt;Secret을 알아보자&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Secret은 민감한 데이터를 저장하기 위해 특별히 설계되었다.&lt;/strong&gt; API Key, 데이터베이스 패스워드, TLS 인증서, OAuth 토근 등이 여기에 해당된다. 따라서 Secret을 사용하면 사용자의 기밀 데이터를 애플리케이션에 넣을 필요가 없다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;주의사항&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Secret은 기본적으로 ETCD에 암호화되지 않고 평문으로 저장된다.&lt;/li&gt;
  &lt;li&gt;그렇기 때문에 API Access 권한이 있는 모든 사용자 또는 etcd에 접근할 수 있는 모든 사용자는 시크릿을 조회하거나 수정할 수 있다.&lt;/li&gt;
  &lt;li&gt;또한 네임스페이스에서 파드 생성 권한이 있는 사람은 누구나 해당 접근을 사용하여 해당 네임스페이스의 모든 시크릿을 읽을 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;권장되는 사용법&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Secret에 대해 Encryption at Rest를 활성화한다.&lt;/li&gt;
  &lt;li&gt;Secret에 대한 최소한의 접근 권한을 지니도록 RBAC 규칙을 활성화 또는 구성한다.&lt;/li&gt;
  &lt;li&gt;특정 컨테이너서만 시크릿에 접근하도록 한다.&lt;/li&gt;
  &lt;li&gt;외부 시크릿 저장소 제공 서비스를 사용하는 것을 고려한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;스펙 정리&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;type&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Opaque:&lt;/code&gt; 가장 일반적인 타입으로 정해진 형식 없는 임의의 데이터를 저장한다.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kubernetes.io/service-account-token:&lt;/code&gt;  ServiceAccount의 자격증명을 저장하며, 자동으로 생성되고 파괴된다.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kubernetes.io/dockerconfigjson:&lt;/code&gt; Private Docker Registry 에 접근하기 위한 인증 정보를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.docker/config.json&lt;/code&gt; 형태로 저장한다. data 필드에 .dockerconfigjson 이라는 Key가 반드시 필요하다.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kubernetes.io/basic-auth:&lt;/code&gt; 기본 인증을 위한 자격증명을 저장한다. data 필드에 username과 password 키가 필요하다.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kubernetes.io/ssh-auth:&lt;/code&gt; SSH 키 페어를 저장한다. data 필드에 ssh-privatekey, ssh-publickey 키가 필요하다.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kubernetes.io/tls:&lt;/code&gt; TLS 인증서와 개인키를 저장한다. Ingress TLS Offloading 등에 사용된다. data 필드에 tls.crt, tls.key 키가 반드시 필요하다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;data&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;Secret의 실제 데이터를 key-value 형태로 저장하는 필드이다. value는 반드시 base64로 인코딩된 문자열이어야 하며, key 이름은 영문, 숫자, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-&lt;/code&gt;,&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_&lt;/code&gt;,&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.&lt;/code&gt; 문자만 포할할 수 있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;stringdata&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;data 필드의 편의성을 위한 필드이다. 여기에 key-value를 일반 문자열로 입력하면 api server가 이를 자동으로 base64 인코딩하여 data 필드에 반영한다. 이 필드는 쓰기 전용 이며, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kubectl get secret -o yaml&lt;/code&gt;  등으로 조회하면 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;stringData&lt;/code&gt; 필드는 보이지 않고 data 필드에 인코딩된 값만 나타난다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;왜-secret과-config를-분리하였을까&quot;&gt;왜 Secret과 Config를 분리하였을까?&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Config나 Secret은 Pod 입장에서 주입받는 방법이나 활용 방법이 크게 다르지 않다. 그렇다면 쿠버네티스는 왜 두 Workload를 분리하여 운영할까?&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;1) 최소 권한:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;RBAC을 통해 Secret 같은 민감 데이터는 접근 제어가 가능해진다. 만약, ConfigMap에 모든 데이터가 다 담긴다면 노출하고 싶지 않은 데이터를 방지할 방법이 복잡해진다.&lt;/li&gt;
  &lt;li&gt;또, 그렇다고 ConfigMap 자체에 접근제한을 걸면 ConfigMap을 공유하거나 이용해야 하는 경우 복잡성이 높아진다. 따라서 ConfigMap에는 민감하지 않는 데이터를 담아 불필요한 접근제어를 제거하고 Secret에만 접근 제어를 진행하여 명확하게 권한 기반으로 제어할 수 있게된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;2) 확장성 및 생태계 통합:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Secret을 별도의 API Kind로 정의한 덕분에 HashiCorp Vault나 AWS Secrets Manager 같은 외부 시스템은 Secret 객체만을 명확한 대상으로 삼는 컨트롤러(예: External Secrets Operator)를 통해 쿠버네티스와 매끄럽게 연동될 수 있다.&lt;/li&gt;
  &lt;li&gt;결과적으로, 이는 단순히 Secret을 외부에 저장하는 것을 넘어, 동적 Secret 생성, 자동 순환, 중앙화된 감사 등 쿠버네티스 네이티브 기능만으로는 어려운 고급 보안 관리 기능을 위임하여 클러스터에 확장할 수 있게 만들어준다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;env와-secret의-주입-방식-이해&quot;&gt;ENV와 Secret의 주입 방식 이해&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;ConfigMap과 Secret을 Pod의 Container에 전달하는 방법은 크게 2가지 방법이 있으며 각 사용의 장단이 뚜렷하다.&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h3 id=&quot;1-환경-변수로-주입&quot;&gt;&lt;strong&gt;1) 환경 변수로 주입&lt;/strong&gt;&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;env 또는 envFrom 필드를 사용해 ConfigMap 이나 Secret의 key-value를 컨테이너 환경 변수로 직접 매핑할 수 있다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;장점&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;사용이 가장 간편하고, 대부분의 애플리케이션의 추가적인 코드 수정 없이 환경 변수로부터 설정을 읽을 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;단점&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Pod이 시작된 후에는 ConfigMap 이나 Secret의 변경 사항이 반영되지 않는다. 업데이트를 적용하려면 파드를 재시작해야 한다.&lt;/li&gt;
  &lt;li&gt;환경 변수는 /proc/[pid]/environ 파일을 통해 Pod 내 다른 프로세스나 권한 있는 사용자에게 노출될 수 있어 보안적으로 덜 안전하다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;예시&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 예시: 특정 key를 선택하여 환경 변수로 주입&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Pod&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;my-pod&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;my-container&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;redis&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;MY_ENV_VARIABLE&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;valueFrom&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;configMapKeyRef&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;my-configmap&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 참조할 ConfigMap 이름&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;my-key&lt;/span&gt;       &lt;span class=&quot;c1&quot;&gt;# 사용할 key&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;2-볼륨-마운트로-주입&quot;&gt;&lt;strong&gt;2) 볼륨 마운트로 주입&lt;/strong&gt;&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;ConfigMap이나 Secret을 정의하고, 이를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;volumeMounts&lt;/code&gt; 를 통해 컨테이너 내부 특정 경로에 파일 형태로 마운트한다. 각 key는 파일명이 되고, value는 해당 파일의 내용이된다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;장점&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Hot Reload가 가능하다. ConfigMap 이나 Secret이 업데이트되면, 잠시 후(kubelet의 동기화 주기에 맞게) Pod 재시작 없이도 컨테이너 내의 파일 내용이 자동으로 동기화된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;단점&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;애플리케이션이 파일 시스템에서 설정을 읽도록 구현되어 있어야 한다.따라서 properties, conf, toml등의 파일을 볼륨 마운트로 Pod에 주입하여 사용하는 방법에 적합하다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;예시&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nn&quot;&gt;---&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ConfigMap&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;test-config&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;APP_NAME&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;MyTestApp&quot;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;DATABASE_HOST&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;db.example.com&quot;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;DATABASE_PORT&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;5432&quot;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;LOG_LEVEL&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;INFO&quot;&lt;/span&gt;
&lt;span class=&quot;nn&quot;&gt;---&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Pod&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;test-pod-volume-only&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;main-container&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;busybox&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;command&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;sh&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-c&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;3600&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;volumeMounts&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;config-volume&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;mountPath&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/etc/config&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;config-volume&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;configMap&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;test-config&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;restartPolicy&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Never&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/config-secret.png&quot; alt=&quot;image.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;그렇다면-왜-두-가지-방식을-지원할까&quot;&gt;그렇다면, 왜 두 가지 방식을 지원할까?&lt;/h2&gt;

&lt;p&gt;결론부터 말하면, 이는 &lt;strong&gt;‘예측 가능한 안정성(Immutability)’과 ’운영상의 유연성(Dynamic Update)’&lt;/strong&gt;이라는, 서로 다른 두 설계 목표를 모두 지원하기 위함이다.&lt;/p&gt;

&lt;h3 id=&quot;1-envenvfrom방식-불변성을-통한-안정성-확보&quot;&gt;&lt;strong&gt;1) &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;env/envFrom 방식:&lt;/code&gt; 불변성을 통한 안정성 확보&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;이 방식으로 주입된 환경 변수는 컨테이너 시작 시 메모리에 주입되어 절대 변하지 않는 &lt;strong&gt;불변(Immutable) 값&lt;/strong&gt;이 된다. 이는 “설정이 바뀌면, Pod를 새로 배포한다”는 &lt;strong&gt;불변 인프라(Immutable Infrastructure) 철학&lt;/strong&gt;을 강제하여, 런타임 중 설정 변경으로 인한 예측 불가능한 오류를 원천적으로 차단한다.&lt;/p&gt;

&lt;p&gt;하지만 이 ‘불변성’이라는 특징 때문에, Pod 재시작 없이는 설정을 변경할 수 없어 동적인 Hot Reload는 지원되지 않는다.&lt;/p&gt;

&lt;h3 id=&quot;2-volumesvolumemounts방식-동적-업데이트를-통한-유연성-확보&quot;&gt;&lt;strong&gt;2) &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;volumes/volumeMounts 방식:&lt;/code&gt; 동적 업데이트를 통한 유연성 확보&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;반면 이 방식은 ConfigMap/Secret을 파일 시스템의 리소스로 마운트한다. Kubelet이 원본 리소스의 변경을 감지하면 마운트된 파일을 원자적으로(atomically) 교체해주므로, 애플리케이션이 이를 감지해 &lt;strong&gt;Pod 재시작 없이 Hot Reload&lt;/strong&gt;하는 것이 가능하다.&lt;/p&gt;

&lt;p&gt;이는 로깅 레벨 변경이나 기능 플래그 전환처럼, 서비스 중단 없이 즉각적인 설정 변경이 필요한 &lt;strong&gt;운영상의 요구&lt;/strong&gt;를 충족시키기 위한 강력한 유연성을 제공한다.&lt;/p&gt;

&lt;h2 id=&quot;env-주입-과정-알아보기&quot;&gt;ENV 주입 과정 알아보기&lt;/h2&gt;

&lt;p&gt;환경 변수가 일단 주입된 후에 불변한 이유는 쿠버네티스의 정책은 아니고 OS의 프로세스 모델의 구조 때문이다. 컨테이너도 OS 관점에서 프로세스이기에 동일훤 원리를 따른다. 보통 새로운 프로세스가 생성될 때,  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fork()&lt;/code&gt;와 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;execve()&lt;/code&gt; 라는 두 개의 System Call을 통해 이루어진다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fork()&lt;/code&gt; 를 실행하면 부모 프로세스는 자신과 똑같은 복제본인 자식 프로세스를 만들고 이 때 자식은 부모의 메모리, 파일 디스크립터, 그리고 환경 변수까지 복사해 물려 받는다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;execve()&lt;/code&gt; 자식 프로세스는 이 시스템 콜을 통해 자기 자신을 새로운 프로세스로 교체하는데, 이 함수를 호출 할 때, 새로운 프로세스에 전달할 초기 환경 변수 목록을 인자로 넘겨준다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이 과정은 컨테이너가 시작될 때도 동일하게 일어난다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kubelet(부모 프로세스) 역할:&lt;/code&gt;   kubelet은 컨테이너 런타임에게 Pod Spec에 정의된 환경 변수 목록을 전달한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;컨테이너 런타임:&lt;/code&gt; 이 정보를 받아 컨테이너 내부에서 실행될 메인 프로세스를 execve()로 실행하면서 전달받은 환경 변수들로 초기화된다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;kubelet의-동작-원리---deep-dive&quot;&gt;Kubelet의 동작 원리 - Deep Dive&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;Kubelet은 ConfigMap/Secret을 컨테이너에 전달하는 실질적인 역할을하는게 그 과정이 어떻게 되는지 조금더 자세히 보자&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;감시:&lt;/code&gt; 각 노드의 kubelet은 Control Plane의 API Server를 지속적으로 Watch 하고 있다. 이 때 자신에게 할당된 (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spec.nodeName&lt;/code&gt;이 자신의 노드 이름인 경우) Pod가 있는지 체크한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Pod 인지 및 명세 확인:&lt;/code&gt; 스케줄러에 의해 특정 Pod이 노드에 할당되면, kubelet은 해당 Pod의 명세를 API Server로 요청하여 읽어들인다. 이 때 어떤 ConfigMap이나 Secret을 필요로 하는지 파악한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;데이터 요청(Fetch):&lt;/code&gt; kubelet은 Pod 명세에 따라 필요한 ConfigMap과 Secret 객체의 내용을 API 서버에 명시적으로 요청하여 가져온다. 이 통신은 TLS로 암호화 되며, kubelet은 ServiceAccount나 인증서를 통해 API 서버로부터 인증/인가를 받아야한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;주입 메커니즘 실행&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;주입-메커니즘-실행&quot;&gt;&lt;strong&gt;주입 메커니즘 실행&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;A. 환경 변수로 주입인 경우&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;kubelet은 가져온 ENV(key-value 데이터)를 메모리를 유지한다.&lt;/li&gt;
  &lt;li&gt;CRI에 컨테이너 생성 요청을 할 때 이 ENV 데이터를 컨테이너 설정의 환경 변수 부분에 포함하여 전달한다.&lt;/li&gt;
  &lt;li&gt;컨테이너 런타임은 이 정보를 받아 컨테이너의 첫 번째 프로세스를 실행할 때 환경 변수로 설정해준다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;B. 볼륨 마운트로 주입인 경우&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;호스트에 디렉토리 생성:&lt;/strong&gt; kubelet은 호스트 노드의 특정 경로(일반적으론 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/var/lib/kubelet/pods/&amp;lt;pod-uid&amp;gt;/volumes/kubertes.io~[configmap|secret]/&amp;lt;volume-name&amp;gt;&lt;/code&gt;) 에 디렉토리를 생성한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;데이터 기록:&lt;/strong&gt; 가져온 데이터의 각 key를 파일이름으로, 각 value를 파일 내용으로 하여 해당 디렉토리에 파일을 생성한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;심볼릭 링크 생성:&lt;/strong&gt; kubelet은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;..data(가칭)&lt;/code&gt; 라는 이름의 심볼릭 링크를 만들어, 방금 생성한 타임스탬프 디렉토리를 가르키도록 한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;컨테이너 마운트:&lt;/strong&gt; Kubelet이 컨테이너 런타임에 컨테이너 생성을 요청할 때, “호스트의 이 경로를 컨테이너 내부의 저 경로(mountPath)로 마운트하라”고 지시하고 컨테이너 런타임이 이 지시에 따라 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;..data&lt;/code&gt;  디렉토리를 컨테이너 바인드 마운트한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;왜-env는-불변하고-volumemount-방식은-가능한가&quot;&gt;왜 ENV는 불변하고 volumeMount 방식은 가능한가?&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;환경 변수는&lt;/strong&gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;execve()&lt;/code&gt; 함수에 의해 &lt;strong&gt;최초 초기화될 때 컨테이너나 프로세스에 각인되며 kubelet에 의해 컨테이너가 시작되면 격리되어 변경할 방법이 없다.&lt;/strong&gt; 프로세스도 마찬가지로 실행되면 다른 프로세스로부터 격리된다. 따라서 환경 변수 값을 수정할 수 있는 방법을 OS 레벨에서 제공하지 않기에 변경할 방법이 없다.&lt;/p&gt;

&lt;p&gt;만약, 이게 가능하다면 프로세스가 다른 프로세스의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PATH&lt;/code&gt; 환경 변수를 마음대로 바꾸거나, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DB_PASSWORD&lt;/code&gt; 를 바꾸는 등의 끔찍한 보안 및 안정성 문제를 일으킬 수 있다. 따라서 프로세스 격리 원칙을 지키기 위해 ENV 값들은 불변하다.&lt;/p&gt;

&lt;h2 id=&quot;볼륨-마운트-방식이-가능한-이유---hot-reload-원리&quot;&gt;&lt;strong&gt;볼륨 마운트 방식이 가능한 이유 - Hot reload 원리&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;반면, 볼륨 마운트를 통한 업데이트가 가능한 이유는 파일 시스템을 마운트 하는 방식이 처음부터 여러 프로세스 간 데이터 공유를 위해 설계된 표준적인 메커니즘이기 때문인데 조금더 자세히 알아보자&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;이유: 심볼릭 링크&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;위에서 말한 것처럼 컨테이너에 마운트되는 것은 심볼릭 링크로 원본 디렉토리를 바라보고 있다.&lt;/li&gt;
  &lt;li&gt;따라서 kubelet은 이를 이용해 심볼릭 링크를 원자적으로 업데이트 하는 방식을 사용하기 때문이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;과정:&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;컨테이너에는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;..data&lt;/code&gt; 심볼릭 링크가 마운트 되어있다. (위에서 설명)&lt;/li&gt;
  &lt;li&gt;ConfigMap/Secret이 업데이트되면, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kubelet&lt;/code&gt; 은 새로운 타임스탬프 디렉토리(2025.v2)를 만들고 새 데이터를 쓴 뒤, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;..data&lt;/code&gt; 심볼릭 링크가 가르키는 대상을 새 디렉토리로 교체한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;주입받은-환경-변수는-프로세스-메모리-중-어떤-영역에-존재할까&quot;&gt;주입받은 환경 변수는 프로세스 메모리 중 어떤 영역에 존재할까?&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;결론:&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;환경 변수는 프로세스의 가상 메모리 중 Stack 세그먼트 위인 가장 높은 주소 영역에 위치한다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;컨테이너의 본질은 프로세스이다. 따라서 컨테이너의 환경 변수는 프로세스와 동일한 메모리 구조로 맵핑된다. 환경 변수는 프로세스의 가상 메모리 중 Stack 세그먼트 위인 가장 높은 주소 영역에 위치하며, 프로세스 생성 시 호출되는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;execve()&lt;/code&gt;System Call 결과 다음과 같은 메모리 구조를 가지게된다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;+------------------------+ &amp;lt;-- Highest Memory Address
| Kernel Space           | (프로세스에서 직접 접근 불가)
+------------------------+
|                        |
| Environment Variables  |
| Command-line Arguments |
+------------------------+
| Stack (스택)            | (아래 방향으로 자람)
|      ↓                 |
+------------------------+
|                        |
| (Unmapped Memory)      |
|                        |
+------------------------+
|      ↑                 |
| Heap (힙)              | (위 방향으로 자람)
+------------------------+
| BSS Segment            |
+------------------------+
| Data Segment           |
+------------------------+
| Text Segment (Code)    |
+------------------------+ &amp;lt;-- Lowest Memory Address
| (Reserved)             |
+------------------------+
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;그렇다면-왜-stack-위일까&quot;&gt;&lt;strong&gt;그렇다면 왜 Stack 위일까?&lt;/strong&gt;&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;불변의 값을 나열하는 것이면 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Text Segment&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Data Segment&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BSS Segment&lt;/code&gt; 사이나 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Heap&lt;/code&gt; 아래여도 될 것 같은데 왜 Stack 위일까?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;초기화 과정과 메모리 영역의 특성을 파악해보자&lt;/p&gt;

&lt;p&gt;프로세스 메모리 영역 구성은 위에서 본 것처럼 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Text&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Data&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BSS&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Heap&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Unmapped Memory&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Stack&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENV&lt;/code&gt; 이렇게 구성되어 있다. 각, 영역의 특성을 이해하면 Stack 위에 위치하는 것이 합리적이다 라는 것을 알 수 있다.&lt;/p&gt;

&lt;p&gt;우선, Text, Data, BSS 영역에 위치하지 않는 이유는 다음과 같다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;프로세스 생성 과정이 복잡해지고 생성 지연을 최소화 하기 위함&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;실행 파일과의 직접적인 매핑&lt;/strong&gt;: 커널의 로더(loader)가 execve를 처리할 때, 디스크에 있는 실행 파일의 Text Segment와 Data Segment를 가상 메모리 공간으로 거의 그대로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mmap()&lt;/code&gt;을 통해 매핑한다.
즉, 파일에서의 연속된 바이트들이 메모리에서도 연속된 공간에 매핑되는데 이는 매우 빠르고 효율적인 작업이다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;가변 크기 데이터의 문제&lt;/strong&gt;: 만약 Text와 Data 세그먼트 사이에 가변 크기인 환경 변수 블록을 삽입한다고 가정해보자&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;과정&lt;/strong&gt;&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;커널은 먼저 Text 세그먼트를 메모리에 매핑해야 한다.&lt;/li&gt;
      &lt;li&gt;그다음, 이번에 실행되는 프로세스의 환경 변수 크기(envp의 총 길이)를 계산해야 한다.&lt;/li&gt;
      &lt;li&gt;계산된 크기만큼의 빈 공간을 확보한다.&lt;/li&gt;
      &lt;li&gt;그리고 그 빈 공간 &lt;em&gt;다음에&lt;/em&gt; Data 세그먼트를 매핑해야 한다.&lt;/li&gt;
    &lt;/ol&gt;

    &lt;p&gt;이 과정은 실행 파일의 내용을 한 번에 쭉 매핑하는 것에 비해 훨씬 복잡하고 비효율적이다 또한, Text와 Data 사이의 거리가 실행 시마다 달라져 디버깅과 프로파일링을 매우 어렵게 만든다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;메모리 권한 설정의 복잡성&lt;/strong&gt;: Text 세그먼트는 보통 읽기/실행(r-x) 권한을, Data와 BSS는 읽기/쓰기(rw-) 권한을 가진다. 세그먼트 사이에 다른 데이터를 끼워 넣는 것은 페이지 단위로 권한을 관리하는 MMU의 설정을 복잡하게 만들고 추가적인 오버헤드를 유발하게 된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;만약, Heap 아래 (즉, BSS와 Heap 사이)에 위치한다면?&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h3 id=&quot;기존-동작-원리&quot;&gt;&lt;strong&gt;기존 동작 원리&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Text, Data, BSS 세그먼트 들은 컴파일 시점에 결정되면 링크 과정을 통해 메모리에 맵핑되며 정적 데이터 영역이 끝나는 지점의 주소를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_end&lt;/code&gt; 또는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;__bss_end_&lt;/code&gt; 와 같은 심볼로 파일 안에 기록해둔다.&lt;/p&gt;

&lt;p&gt;또, 메모리 동적 할당을 담당하는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;libc&lt;/code&gt; 의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;malloc&lt;/code&gt; 구현을 보면 커널에게 물어볼 필요 없이 실행 파일 안에 기록된 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_end&lt;/code&gt;  심볼의 주소를 읽어, 정적 데이터의 끝점을 알게되고 힙의 시작점을 고정할 수 있다.&lt;/p&gt;

&lt;p&gt;그런데 BSS와 Heap 사이에 ENV (동적인 사이즈)가 배치된다면 libc의 malloc 초기화 과정에 힙의 시작점을 알기 위해 반드시 커널과 소통해야 한다. (libc는 유저 스페이스의 라이브러리이고, ENV 초기화는 execve 라는 커널 영역의 책임이다.)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;어떻게? 커널이 execve의 결과로 새로운 힙 시작 주소를 프로세스에게 넘겨주거나, libc가 ”내 힙은 어디서 시작합니까?”라고 묻는 새로운 시스템 콜을 호출해야 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 방식은 커널과 libc 사이에 의존성을 만들고 커널은 유저 스페이스 라이브러리인 malloc의 구현 방식을 고려해야 하며, libc는 커널이 제공하는 새로운 인터페이스에 의존해야 한다. 이렇게 되면 전체적인 시스템의 복잡도가 증가하고 유연성이 떨어진다.&lt;/p&gt;

&lt;h3 id=&quot;왜-스택은-괜찮은가&quot;&gt;&lt;strong&gt;왜 스택은 괜찮은가?&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;스택(Stack)&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;관리 주체&lt;/strong&gt;: &lt;strong&gt;CPU(하드웨어)&lt;/strong&gt; 와 커널&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;관리 방식&lt;/strong&gt;: ESP/RSP 라는 &lt;strong&gt;스택 포인터(Stack Pointer) CPU 레지스터&lt;/strong&gt;를 통해 관리됩니다.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;초기화&lt;/strong&gt;: execve 시점에 커널이 환경 변수, 인자 등을 모두 스택의 최상단에 쌓은 후, 그 최종 주소를 &lt;strong&gt;RSP 레지스터에 딱 한번 설정&lt;/strong&gt;해 줍니다.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;이후 동작&lt;/strong&gt;: 그 후부터는 프로그램의 call, ret, push, pop 같은 기계어 명령어에 의해 RSP 레지스터 값이 &lt;strong&gt;하드웨어 레벨에서 자동으로&lt;/strong&gt; 증가하거나 감소합니다. 유저스페이스 라이브러리가 스택의 시작점을 알 필요가 없습니다. CPU가 알아서 다 해줍니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;힙(Heap)&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;관리 주체&lt;/strong&gt;: &lt;strong&gt;libc (소프트웨어)&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;관리 방식&lt;/strong&gt;: malloc, free 함수 내부의 복잡한 알고리즘(free list, bins 등)을 통해 관리됩니다. 힙에는 CPU 레지스터 같은 하드웨어 지원이 없습니다. 순수 소프트웨어의 영역입니다.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;초기화&lt;/strong&gt;: libc는 자신의 소프트웨어 자료구조를 초기화하기 위해 &lt;strong&gt;“힙이 어디서부터 시작되는가”&lt;/strong&gt; 라는 기준점 정보가 반드시 필요합니다. 이 정보를 가장 간단하고 독립적으로 얻는 방법이 바로 컴파일 타임에 약속된 _end 심볼을 사용하는 것입니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;요약하자면, 스택은 커널이 하드웨어(CPU 레지스터)에 초기값을 설정해주면 그만이지만, 힙은 소프트웨어(libc)가 자신의 관리 체계를 시작하기 위해 고정된 기준점이 필요하다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;왜-secret은-base64로-인코딩-할까&quot;&gt;&lt;strong&gt;왜 Secret은 Base64로 인코딩 할까?&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;Secret 데이터 base64로 인코딩하는 것은 보안적인 측면에서 불안 요소이다. 그럼 왜 base64로 인코딩 하는 형태로 설계되었을까?&lt;/p&gt;

&lt;p&gt;&lt;em&gt;이 고민의 핵심 base64로 인코딩 하는 것이 보안과는 관련이 없다는 점을 파악하는 것이다.&lt;/em&gt; 결론은 &lt;em&gt;Secret의 data 필드는 임의의 바이너리 데이터를 담을 수 있게 설계되었기 때문에 base64 기반의 인코딩을 지원한다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;YAML이나 JSON 형식의 매니페스트 파일은 기본적으로 Text 기반인데 줄바꿈이나 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;null 문자(\0)&lt;/code&gt; 또는 기타 제어 문자가 포함된 바이너리 데이터(예: id_rsa 개인키, .p12 인증서 파일 등)를 그대로 넣으면 파싱 오류가 발생하거나 데이터 변형이 초래될 수 있다.&lt;/p&gt;

&lt;p&gt;이런 문제를 해결하고자 base64를 활용한다. base64는 모든 바이너리 데이터를 ASCII로 변환하고 이렇게 변환된 문자열은 YAML/JSON 파일에 아무런 문제 없이 포함될 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;왜-기본적으로-암호화하지-않았을까&quot;&gt;&lt;strong&gt;왜 기본적으로 암호화하지 않았을까?&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;유연성과 확장성을 중시하기 때문&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;쿠버네티스는 핵심 설계 원칙 중 하나로 &lt;em&gt;‘확장 가능성’&lt;/em&gt;을 내세우고 있다. 만약, 쿠버네티스가 특정 암호화 방식을 내장하여 강제했다면 사용자들은 환경에 맞는 최적의 KMS(Key Management Solution)를 도입하는데 큰 제약을 겪게될 것이다.&lt;/p&gt;

&lt;p&gt;대신 쿠버네티스는 Encryption at Reset 이라는 플러그형 메커니즘을 제공한다. 사용자는 자신의 환경에 맞는 KMS Provider를 선택하여 API Server와 연동할 수 있고 이를 통해 쿠버네티스는 특정 기술에 종속되지 않으면서도, 강력한 보안을 지원할 수 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;결론&quot;&gt;&lt;strong&gt;결론&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;Kubernetes의 ConfigMap과 Secret은 단순히 설정과 민감 정보를 컨테이너에 전달하는 수단을 넘어, 클라우드 네이티브 환경의 핵심 설계 철학을 담고 있는 중요한 API 오브젝트이다. 이 글을 통해 우리는 표면적인 사용법에서 시작하여, &lt;em&gt;두 리소스가 분리된 이유&lt;/em&gt;, &lt;em&gt;두 가지 주입 방식이 제공하는 상반된 가치&lt;/em&gt;, 그리고 이 모든 것이 운영체제의 프로세스 모델과 메모리 구조에 어떻게 뿌리내리고 있는지 깊이 이야기해보았다.&lt;/p&gt;

&lt;p&gt;이 과정에서 알게된 것들은 다음과 같다.
&lt;strong&gt;ConfigMap과 Secret의 본질&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ConfigMap과 Secret은 12-Factor App의 설정 외부화 원칙을 구현하는 Kubernetes API 오브젝트이다.&lt;/li&gt;
  &lt;li&gt;두 리소스의 분리는 RBAC을 통한 접근 제어 차별화와 보안 정책의 세분화를 위함이다.&lt;/li&gt;
  &lt;li&gt;Secret의 Base64 인코딩은 암호화가 아닌 바이너리 데이터 호환성을 위한 인코딩 방식이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;두 가지 주입 방식의 근본적 차이&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;환경 변수 방식&lt;/strong&gt;: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;execve()&lt;/code&gt; 시스템 콜에 의해 프로세스 시작 시점에 고정되어 불변성(Immutability)을 보장한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;볼륨 마운트 방식&lt;/strong&gt;: Kubelet의 symlink 교체를 통해 동적 업데이트(Hot Reload)가 가능하며 유연성을 제공한다.&lt;/li&gt;
  &lt;li&gt;이 두 방식은 ‘안정성 vs 유연성’이라는 상반된 설계 목표를 모두 지원하기 위한 의도적인 선택이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;프로세스 메모리와 환경 변수의 관계&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;환경 변수는 프로세스 메모리의 Stack 세그먼트 위 가장 높은 주소 영역에 위치한다.&lt;/li&gt;
  &lt;li&gt;execve() 호출 시 커널이 환경 변수를 메모리에 복사하며, 이후 프로세스 생명주기 동안 변경되지 않는다.&lt;/li&gt;
  &lt;li&gt;Text, Data, BSS 세그먼트는 컴파일/링크 타임에 크기가 결정되므로, 런타임에 결정되는 환경 변수와는 별도 영역에 배치된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Kubelet의 동작 메커니즘&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Kubelet은 API 서버를 지속적으로 Watch하여 ConfigMap/Secret 변경을 감지한다.&lt;/li&gt;
  &lt;li&gt;볼륨 마운트 시 새로운 타임스탬프 디렉터리를 생성하고 symlink를 원자적으로 교체하여 Hot Reload를 구현한다.&lt;/li&gt;
  &lt;li&gt;이 방식은 파일 시스템 수준에서 일관성을 보장하며, 애플리케이션이 부분적으로 업데이트된 설정을 읽는 것을 방지한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;보안과 확장성 설계&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Secret은 기본적으로 ETCD에 암호화되지 않고 평문으로 저장되지만, Encryption at Rest를 통해 강화할 수 있고 권장된다.&lt;/li&gt;
  &lt;li&gt;External Secrets Operator와 같은 확장 도구를 통해 HashiCorp Vault, AWS Secrets Manager 등과 통합 가능하다.&lt;/li&gt;
  &lt;li&gt;이는 Kubernetes가 특정 보안 솔루션을 강요하지 않고 확장 가능한 플랫폼을 지향한다는 설계 철학을 보여준다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;운영 환경에서의 고려사항&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;환경 변수는 프로세스 격리를 위해 불변하지만, 이로 인해 동적 설정 변경이 불가능하다.&lt;/li&gt;
  &lt;li&gt;볼륨 마운트는 Hot Reload가 가능하지만, 애플리케이션이 파일 변경을 감지하고 처리하는 로직이 필요하다.&lt;/li&gt;
  &lt;li&gt;두 방식 모두 장단점이 있으므로, 애플리케이션의 특성과 운영 요구사항에 따라 적절한 방식을 선택해야 한다.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="Kubernetes" /><category term="DevOps" /><summary type="html">쿠버네티스의 ConfigMap, Secret 를 깊게 이해하고 왜 둘을 분리했는지 깊게 이해하고자 합니다.</summary></entry><entry><title type="html">왜 쿠버네티스를 도입 했는가?</title><link href="https://tech.k10n.me/2025/07/07/why-kubernetes.html" rel="alternate" type="text/html" title="왜 쿠버네티스를 도입 했는가?" /><published>2025-07-07T00:00:00+00:00</published><updated>2025-07-23T00:39:24+00:00</updated><id>https://tech.k10n.me/2025/07/07/why-kubernetes</id><content type="html" xml:base="https://tech.k10n.me/2025/07/07/why-kubernetes.html">&lt;p&gt;회사에서 쿠버네티스 기반으로 서비스를 약 1년정도 운영 중인 상태입니다. 2024년의 비즈니스 목표는 &lt;strong&gt;‘우리 Platform을 Boxing하여 고객사에 딜리버리 하고 운영하는 것’&lt;/strong&gt;이었습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;목표:&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;실제 고객사의 보안 요구사항을 충족 시키며 &lt;strong&gt;“우리 Platform을 ‘전달’ 하고 ‘운영’ 해야 한다.” (No Inbound Only OutBound)&lt;/strong&gt;&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h3 id=&quot;돌아보면&quot;&gt;&lt;strong&gt;돌아보면:&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;이 문제를 해결해야 할 때쯤인 23년 후반기에 팀장님 새롭게 오셨습니다. 새로오신 팀장님의 주요 커리어는 클라우드와 쿠버네티스였고 팀장님이 쿠버네티스를 잘 아신다는 이유로 쿠버네티스를 이용해 해결하고자 했습니다. 결론적으로 총 2개의 고객사에 쿠버네티스를 기반의 플랫폼 Boxing하여 딜리버리하였고 프로젝트를 성공적으로 운영하여 25년에도 다른 프로젝트들을 함께하게 되었습니다.&lt;/p&gt;

&lt;p&gt;하지만 이 글의 트리거 라고 볼 수 있는데 지금 생각해보면 아쉬운 점이 존재합니다. &lt;strong&gt;“왜 쿠버네티스를 사용했나요?”&lt;/strong&gt; 라고 질문한다면 논리적으로 대답하기 어렵고 스스로도 납득하기도 어렵습니다. 따라서 이 글을 작성하며 조금더 학습하며 앞으로  0 → 1 을 넘어 1 → 10 경험을 쌓을 수 있게 노력해볼 예정입니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;쿠버네티스란-무엇인가&quot;&gt;&lt;strong&gt;쿠버네티스란 무엇인가?&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;먼저, 쿠버네티스란 무엇이고 어떤 문제를 해결하기 위해 등장한 기술인지 알아보고자 합니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;Kubernetes is an open-source container orchestration system for automating software deployment, scaling, and management&lt;/em&gt;&lt;br /&gt;
by Wiki&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;쿠버네티스에 대한 정의를 위키 백과에서는 &lt;strong&gt;&lt;em&gt;“소프트웨어의 자동화된 배포와 스케일링 그리고 운영을 위한 오픈 소스 컨테이너 오케스트레이션 시스템이라 정의합니다.”&lt;/em&gt;&lt;/strong&gt;  즉, 쿠버네티스는 자동화된 컨테이너 운영 관리 도구인 것입니다. &lt;strong&gt;‘오케스트레이션’&lt;/strong&gt; 이란 키워드가 등장하는데 그렇다면 오케스트레이션이란 무엇이고 보편적인 자동화와는 어떤 차이가 있기에 오케스트레이션이란 단어를 사용할까요?&lt;/p&gt;

&lt;h3 id=&quot;automation-vs-orchestration&quot;&gt;&lt;strong&gt;Automation vs Orchestration&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Automation 은 무언가를 새롭게 ‘배포’하고 메트릭을 ‘감지’ 하는 것에 집중합니다.&lt;/strong&gt;  즉, 자동화는 손쉽게 배포하고 이상 지표를 자동으로 감지할 수 있는 시스템을 만드는 것까지가 목표입니다. 하지만 운영/관리를 위해서는 보편적인 자동화로는 한계가 존재하는데 보편적인 자동화만으로는 이상 지표가 감지 되었을 때, 적절한 ‘후속 조치’를 사람이 진행해야 한다는 한계가 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;수동-조취-케이스&quot;&gt;&lt;strong&gt;[수동 조취 케이스]&lt;/strong&gt;&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;컨테이너 내려간 경우, 서버에 접근하여 문제 있는 컨테이너를 제거하고 다시 컨테이너를 올려주어야 한다.&lt;/li&gt;
  &lt;li&gt;트래픽 증가로 인한 부하가 늘어나는 경우, 수동으로 컨테이너 수를 증가시킨다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이처럼 서비스를 운영 시 문제가 생겼을 때 후속 조취 작업은 필수인데 이러한 작업이 ‘사람’에 의존적이라면 실수할 여지가 있으며 이는 곧 ‘ 서비스 품질이 사람에 의해 바뀔 수 있다는 것입니다.’ &lt;strong&gt;보편적인 자동화는 한계가 있고 이는 우리가 추구하는 완벽한 의미에서 자동화는 아닙니다. 따라서 O&lt;em&gt;rchestration&lt;/em&gt;은 후속 조치에 대한 것까지 자동화 해주는 것을 목표로 등장하였고 컨테이너 환경에서는 필수적인 기능들이 되었습니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;쿠버네티스는 오케스트레이션 도구로서 ‘Self Healing’ 을 통해 컨테이너를 지속적으로 정상 상태로 복구시켜주고 부하가 늘어나 처리량이 떨어지면, HPA를 통해 ‘Auto Scaling’&lt;strong&gt;을 셀프로&lt;/strong&gt; 진행합니다. 이렇게 &lt;strong&gt;쿠버네티스는 사람이 진행하던 ‘후속 조취’를 자체적으로 제공하기 때문에 휴먼 에러로 인한 품질이 저하가 발생하지 않으며, 보다 완벽한 자동으로 제공하기 때문에 엔지니어의 운영 코스트를 절감 시켜 다른 생산적인 작업에 리소스를 투입할 수 있게 해줍니다.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;그-외-어떤-도구들이-있을까&quot;&gt;&lt;strong&gt;그 외 어떤 도구들이 있을까?&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;쿠버네티스는 컨테이너를 오케스트레이션 하는 도구이며 쉽게 생각하면 컨테이너 관리 도구입니다. 따라서 컨테이너 관리를 위해 꼭 쿠버네티스만을 사용해야 하는 것은 아닙니다. 오히려 단순 컨테이너를 관리하는 것이 목적이면 꼭 쿠버네티스를 사용할 필요는 없으며 대표적으로 아래의 대안들이 존재합니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Docker Compose&lt;/li&gt;
  &lt;li&gt;Docker Swarm&lt;/li&gt;
  &lt;li&gt;AWS ECS&lt;/li&gt;
  &lt;li&gt;서버리스 서비스들&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이렇게 가장 간단한 Docker Compose 부터 AWS의 ECS 그리고 다양한 서버리스 제품들까지 대안이 존재합니다. 실제로 저희도 Docker Compose만으로 간단한 3tier architecture를 사용했었습니다. 하지만 Docker Compose 만으로는 위 문제들을 해결할 수 없었고 컨테이너 기반으로 서비스를 더 잘 운영하기 위해선 쿠버네티스가 많은 도움을 준다고 생각하여 쿠버네티스를 도입하였습니다.&lt;/p&gt;

&lt;p&gt;추가로 클라우드 환경이라면 컨테이너 오케스트레이션 도구로 AWS ECS 또한 강력합니다. 하지만 ECS는 결국 AWS 의존성이 높고 이식성이 떨어지며 쿠버네티스의 서비스와 같은 로드밸런서의 부재로 컨테이너 레벨에서 로드밸런싱과 서비스 디스커버리 측면에서 한계가 뚜렷합니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;그렇다면-무엇이-쿠버네티스를-표준으로-만들었고-우리가-쿠버네티스를-사용하는-이유&quot;&gt;그렇다면 무엇이 쿠버네티스를 표준으로 만들었고 우리가 쿠버네티스를 사용하는 이유!&lt;/h1&gt;

&lt;p&gt;대안들이 존재하지만 쿠버네티스는 컨테이너 오케스트레이션 표준이되었다. 무엇이 컨테이너 오케이스트레이션 도구에서 표준으로 자리 잡게 했을까요?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/kubernetes.png&quot; alt=&quot;Image&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;높은 이식성과 쿠버네티스 에코시스템:&lt;/strong&gt;
    &lt;ol&gt;
      &lt;li&gt;쿠버네티스를 사용하면 다양한 클라우드 환경 및 온프레미스 환경에서도 일관된 방식으로 애플리케이션을 배포하고 운영할 수 있게 해줍니다.&lt;/li&gt;
      &lt;li&gt;쿠버네티스는 CNCF에서 관리하는 오픈소스이기 때문에 기능들이 빠르게 확장되고 있으며 커뮤니티기반의 강력한 에코 시스템을 확보했습니다. 이러한 에코 시스템들은 운영에 대한 코스트를 낮춥니다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;클러스터링:&lt;/strong&gt;
    &lt;ol&gt;
      &lt;li&gt;쿠버네티스는 Control Plane, Data Plane으로 크게 두 가지 클러스터링을 지원합니다. 따라서 하나의 노드가 Down되어도 나머지 정상 노드를 활용해 비즈니스를 가동시킬 수 있습니다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;유연한 스케줄링:&lt;/strong&gt;
    &lt;ol&gt;
      &lt;li&gt;쿠버네티스는 단순한 스케줄링이 아니라 Node의 상태에 따라 최선의 스케줄링을 하고자 노력합니다.&lt;/li&gt;
      &lt;li&gt;쿠버네티스는 Application의 특성을 고려해 유연한 스케줄링을 제공합니다. 예를 들어 AI 기능이 필요하다면 GPU가 설치된 노드에 배치하는 것이 가능하며, 토폴로지를 제공해 내결함성을 높일 수 있습니다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;손쉬운 네트워크 관리:&lt;/strong&gt;
    &lt;ol&gt;
      &lt;li&gt;쿠버네티스는 CNI 플러그인이라는 가상의 네트워크를 활용해 컨테이너간 통신 컨테이너에 IP 할당 등등 다양한 네트워크 문제를 외부 의존성 없이 자체적으로 해결할 수 있게 지원합니다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;서비스 디스커버리와 로드 밸런싱:&lt;/strong&gt;
    &lt;ol&gt;
      &lt;li&gt;Pod들이 동적으로 생성되고 소멸되기 때문에, 서비스 간 통신을 IP 기반이 아닌 DNS 기반으로 통신할 수 있게 지원합니다.&lt;/li&gt;
      &lt;li&gt;쿠버네티스는  로드 밸런싱을 이용해 Reliability를 높일 수 있는데, Not Ready 상태의 Pod들은 트래픽에서 자동으로 제외시켜 고객의 실패 경험을 최소화 시킬 수 있습니다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;셀프 힐링과 오토스케일링:&lt;/strong&gt;
    &lt;ol&gt;
      &lt;li&gt;내부적으로 제어루프 개념이 존재하기 때문에 Pod가 죽었을 때와 같이 Desired State에서 달라졌을 때 자동으로 Pod를 생성하는 등의 &lt;strong&gt;현재 상태가 목표 상태와 일치하도록 시스템을 조정&lt;/strong&gt;하는 방식으로 작동한다.&lt;/li&gt;
      &lt;li&gt;Application의 처리량이 떨어져 Latency가 늘어난다면 HPA, VPA를 사용해 탄력적인 스케일 인/아웃 을 지원합니다. 나아가 Node의 Resource Pressure에도 Cluster Autoscaler를 사용해 노드 자체도 동적으로 조절할 수 있습니다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;볼륨 관리:&lt;/strong&gt;
    &lt;ol&gt;
      &lt;li&gt;PV와 PVC를 분리하여 스토리지 기술과 애플리케이션의 커플링을 줄입니다. 이를 통해 컨테이너는 Row Level의 Storage 기술에 종속적이지 않고 PVC 만을 사용해 유연하게 볼륨을 구축할 수 있습니다.&lt;/li&gt;
      &lt;li&gt;이러한 특징은 이식성을 높이며, 비교적 비용이 높은 Raw Level의 기술 변경에도 안정성을 제공합니다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;최적화된 GitOps:&lt;/strong&gt;
    &lt;ol&gt;
      &lt;li&gt;쿠버네티스는 Desired State를 유지하고자 합니다. 또 이러한 Desired State는 YAML 파일을 사용하여 선언적인 방식으로 관리됩니다.&lt;/li&gt;
      &lt;li&gt;따라서 형상 코드의 형태로 (IaC) Git을 &lt;strong&gt;Source of Truth로&lt;/strong&gt; 이용해 관리하며 손쉬운 롤백과 히스토리 추적을 지원하여 신뢰성을 높일 수 있습니다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이러한 매커니즘들은 결국 컨테이너 환경에서 서비스를 운영할 때 고민해야하는 것들입니다. 이러한 고민들에 대한 해답을 쿠버네티스가 가장 잘 지원하기 때문에 쿠버네티스가 핵심이자 표준이 되었다 생각합니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;다시-생각해보는--우리는-왜-쿠버네티스를-선택했나&quot;&gt;다시 생각해보는,  ‘우리는 왜 쿠버네티스를 선택했나’&lt;/h2&gt;

&lt;p&gt;위에서 쿠버네티스가 무엇이고 왜 표준이 되었는지 쿠버네티스의 강점들을 정리했습니다. 물론 쿠버네티스가 ‘실버 불릿’은 아니기 때문에 트레이드 오프가 발생하지만, 지금 다시 의사결정을 하라고 해도 쿠버네티스를 선택할 것 같습니다. 그렇다면 왜 그런 선택을 할지 한 번 정리해보겠습니다.&lt;/p&gt;

&lt;p&gt;만약, 지금 다시 의사결정을 해야 한다면 Docker Swarm과 비교해볼 수 있을 것 같습니다. Docker Swarm은 Docker engine에 내장되어있는 Cluster management, Orchestration Tool이며 Kubernetes 처럼 클러스터링을 지원하며 어느정도의 셀프 힐링도 지원합니다. 하지만 도커스웜은 소규모 서비스에 적합하다 라는 내용을 쉽게 볼 수 있습니다. 왜 그럴까요?&lt;/p&gt;

&lt;h3 id=&quot;도커-스웜의-한계점&quot;&gt;&lt;strong&gt;[도커 스웜의 한계점]&lt;/strong&gt;&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;서비스 신뢰성을 보장하기엔 부족한 기능들:&lt;/strong&gt; 서비스의 신뢰성을 위해선 &lt;strong&gt;‘고가용성’&lt;/strong&gt; 과 &lt;strong&gt;‘확장성’&lt;/strong&gt;이 중요한 포인트입니다. 도커 스웜은 컨테이너 레벨에서의 복구를 지원하지만 많이 부족합니다. (PDB도 없음)
무엇보다 컨테이너에 대한 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Health Check&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Readiness&lt;/code&gt; 기능이 없기 때문에 겉으로는 문제가 없지만 내부족으로 컨테이너가 비정상적으로 동작하고 있을 때, 트래픽이 문제의 컨테이너에도 전달되기 때문에 트래픽이 지속적으로 실패할 수 있습니다. 반면, K8s는 자동으로 비정상 파드를 트래픽 대상에서 지워 실패 경험을 최소화 합니다.&lt;/p&gt;

    &lt;p&gt;또, 노드 레벨에서 장애가 났을 때 조취하는 것이 부족합니다. 쿠버네티스는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Unready&lt;/code&gt; 상태의 노드가 발견되면 즉시,  정상적인 상태의 노드로 파드의 스케줄링을 다시합니다. 이렇게 K8s는 신뢰성을 높일 수 있는 여러가지 자동화 매커니즘이 존재하지만 도커 스웜은 부족합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;부족한 리소스 타입:&lt;/strong&gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StatefulSet&lt;/code&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DaemonSet&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Job&lt;/code&gt; 등등 쿠버네티스에는 단순 컨테이너를 넘어 컨테이너를 활용해 보다 다양한 종류의 서비스를 운영할 수 있습니다. 컨테이너는 Stateless 하다는 특징이 있는데 이는 큰 장점이지만 단점이 될 때도 있습니다.&lt;/p&gt;

    &lt;p&gt;예를 들어 DB 같은 서비스는 Stateful 해야 하며 Stateful한 리소스들의 고유성을 보장하고 몇번을 스케줄링해도 동일한 노드에 스케줄링 해줍니다. 하지만 도커 스웜은 이러한 기능들이 존재하지 않아 애플리케이션 성격에 따라 유연한 대처가 불가능합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;부족한 배포 시스템:&lt;/strong&gt; Kubernetes에는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Deployment&lt;/code&gt; 를 이용해 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RollingUpdate&lt;/code&gt;를  기본적으로 지원합니다. Docker Swarm도 service update로 가능하지만 세밀한 제어가 부족합니다. 쿠버네티스는 graceful down을 지원할 수 있으며, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;maxUnavailable&lt;/code&gt; 를 통해 최소로 유지할 파드를 선언해, 서비스의 순단을 방지합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;스케줄링 유연도가 떨어진다:&lt;/strong&gt; 쿠버네티스는 어피니티를 통해 선호하는 곳으로 컨테이너를 스케줄링할 수 있게 도우며 토폴로지를 지원해 분산 배치를 지원 하지만 도커 스웜에는 이러한 기능이 없습니다. 나아가 Resource에 대한 Request가 없어 최소한의 자원을 보장받는 것도 어렵습니다.&lt;/p&gt;

    &lt;p&gt;그 외 Node가 Pressure를 받을 경우, Evict 되어야할 필요가 있는데 이 경우, QoS 클래스라는 개념을 이용해 Evict 우선 순위를 결정하여 주요 서비스의 컴퓨팅 리소스를 최대한 안전하게 지킬 수 있습니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이렇게 도커 스웜은 많은 부분에서 오케스트레이션 도구의 표준이 되기 어려운 형태입니다. 이러한 부족함은 고객사의 폐쇄망에 서비스를 전달하고 운영하는데 있어 신뢰도를 갖추기 어렵다. 판단됩니다. 따라서 지금에서 의사결정을 해도 쿠버네티스를 선택할 것 같습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;어떤-트레이드-오프를-가져야할까---앞으로의-숙제&quot;&gt;어떤 트레이드 오프를 가져야할까? - 앞으로의 숙제&lt;/h2&gt;

&lt;p&gt;지금까지 쿠버네티에 대해 정리하고 도커 스웜과 비교하며 쿠버네티스 라는 의사결정 배경을 고민해봤습니다. 아시겠지만 쿠버네티스를 도입했다고 끝이 아닙니다. 쿠버네티스는 복잡도가 높으며 특히나 EKS처럼 Managed가 아니기 때문에 많은 부분을 신경써야만 보다 안정적인 운영이 가능해집니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;가시성을 높여야합니다.&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;비즈니스를 담당하는 애플리케이션의 가시성, 클러스터 운영의 Core인 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Control Plane&lt;/code&gt; 에 대한 가시성 모두 챙겨야합니다. 관리하는 Workload들이 늘어날 수록 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Control Plane&lt;/code&gt; 의 부하는 높아지고 Control Plane이 죽으면 전체 장애로 이어집니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;물리 머신 레벨에서도 최대한 무중단를 지원해야 합니다.&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;쿠버네티스 버전 업, 노드의 장애로 인한 교체 과정에서 비즈니스는 자체가 완전히 멈추는 것을 피하고자 최대한 무중단을 지원할 수 있어야 합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;이를 통해 클러스터에 대한 MTTR를 높이고 SLA를 준수할 수 있게 노력해야 합니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;마무리&quot;&gt;마무리&lt;/h2&gt;

&lt;p&gt;지금까지 머리속에 뒤죽박죽으로 있던 것들을 정리해봤습니다. 이 과정에서 처음 목표 했던 Why에 대한 답변도 생긴 것 같습니다. 특히, 도커 스웜의 한계점을 명확히 이해하고 우리가 왜 쿠버네티스를 선택해야 했는지 보다 명확해진 시간이었던 것 같습니다.&lt;/p&gt;

&lt;p&gt;앞으로는 쿠버네티스 클러스터 구축의 모범 사례도 학습하며 우리의 약점들을 어떻게 보완할 수 있을지 고민해보도록 할 예정입니다.&lt;/p&gt;</content><author><name></name></author><category term="Kubernetes" /><category term="DevOps" /><summary type="html">쿠버네티스의 강점과 트레이드 오프를 고민하며 쿠버네티스 도입 이유를 공유한다.</summary></entry></feed>